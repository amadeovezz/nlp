{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-12T22:08:21.602544Z",
     "start_time": "2024-01-12T22:08:21.595307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Third party\n",
    "import importlib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# User\n",
    "import importlib\n",
    "import base.encode\n",
    "import attention\n",
    "importlib.reload(base.encode)\n",
    "importlib.reload(attention)\n",
    "\n",
    "from base.encode import get_encoder_decoder\n",
    "from attention import AttentionHead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[35, 53, 59, 50, 42, 1, 63, 53, 59]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder = get_encoder_decoder(training_data=\"../data/shakespear.txt\", type='character')\n",
    "encoder(\"Would you\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T21:06:31.513252Z",
     "start_time": "2024-01-12T21:06:31.484806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "with open(\"../data/shakespear.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "data = torch.tensor(encoder(text), dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T21:06:32.472097Z",
     "start_time": "2024-01-12T21:06:32.392273Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "([35, 53, 59, 50, 42, 1, 63, 53, 59],\n tensor([[-0.4347, -1.3366],\n         [ 1.8144, -0.6323],\n         [-1.5828,  0.8516],\n         [ 0.1660, -1.2911],\n         [ 1.1486, -0.8606],\n         [-1.5051,  1.3237],\n         [-0.3302,  0.2649],\n         [ 1.4611, -0.0145],\n         [ 0.4822,  0.7296]], dtype=torch.float64),\n torch.Size([9, 2]))"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "\n",
    "data = \"Would you\"\n",
    "input_length = len(data)\n",
    "input_embedding_dim = 2\n",
    "\n",
    "encoded_input = encoder(data)\n",
    "input_embedded = torch.randn(size=(len(data), input_embedding_dim), dtype=torch.float64)\n",
    "encoded_input, input_embedded, input_embedded.shape\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T22:08:49.561534Z",
     "start_time": "2024-01-12T22:08:49.556713Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0.7021,  1.1265, -0.2485],\n         [ 0.7015,  1.1229, -0.2499],\n         [ 0.2763, -1.5404, -1.2742],\n         [-0.3931,  1.1916,  1.2198],\n         [-0.3896,  1.1910,  1.2149],\n         [ 0.2805, -1.5157, -1.2651],\n         [ 0.3364, -0.8746, -0.9579],\n         [-0.3318,  0.8022,  0.9089],\n         [ 0.2040, -1.3677, -1.0775]], dtype=torch.float64),\n tensor([[    1.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n              0.0000,     0.0000,     0.0000],\n         [    0.9986,     0.0014,     0.0000,     0.0000,     0.0000,     0.0000,\n              0.0000,     0.0000,     0.0000],\n         [    0.0003,     0.9997,     0.0000,     0.0000,     0.0000,     0.0000,\n              0.0000,     0.0000,     0.0000],\n         [    0.0023,     0.0000,     0.9975,     0.0001,     0.0000,     0.0000,\n              0.0000,     0.0000,     0.0000],\n         [    0.0051,     0.0000,     0.9943,     0.0006,     0.0000,     0.0000,\n              0.0000,     0.0000,     0.0000],\n         [    0.0000,     0.9684,     0.0000,     0.0002,     0.0314,     0.0000,\n              0.0000,     0.0000,     0.0000],\n         [    0.0499,     0.5270,     0.0101,     0.0958,     0.2632,     0.0102,\n              0.0437,     0.0000,     0.0000],\n         [    0.0579,     0.0128,     0.3505,     0.0365,     0.0199,     0.3988,\n              0.1018,     0.0218,     0.0000],\n         [    0.0033,     0.5788,     0.0002,     0.0133,     0.1258,     0.0003,\n              0.0039,     0.2492,     0.0252]], dtype=torch.float64))"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 9x2  2x3 -> 9x3 * 3x9\n",
    "out_dimension = 3\n",
    "a = AttentionHead(input_embedding_dim, out_dimension, block_type=\"decoder\")\n",
    "\n",
    "embeddings, scores = a(input_embedded) #9x3\n",
    "\n",
    "# 9x2 (Input) x 2x3 queries/keys -> 2x9 (Input) x 9x3 (All inputs transposed)  = 2x7 (Inputs weighted)\n",
    "# 9x7 (Q) x 9x7 (K) -> 9x7 7x9 (Inputs weighted x inputs weighted) -> 9x9 (Final input matrix)\n",
    "# 9x9 x 9x3 -> 9x3\n",
    "embeddings, scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T22:08:51.800549Z",
     "start_time": "2024-01-12T22:08:51.794193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
