{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:30:41.300984Z",
     "start_time": "2023-12-13T20:30:41.294793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Third party\n",
    "import importlib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# User\n",
    "import importlib\n",
    "import base.encode\n",
    "import attention\n",
    "importlib.reload(base.encode)\n",
    "importlib.reload(attention)\n",
    "\n",
    "from encode import get_text_encoder_decoder\n",
    "from attention import AttentionHead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[35, 53, 59, 50, 42, 1, 63, 53, 59]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder = get_text_encoder_decoder(training_data=\"../data/shakespear.txt\", type='character')\n",
    "encoder(\"Would you\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:11:02.631727Z",
     "start_time": "2023-12-13T20:11:02.616888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "with open(\"../data/shakespear.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "data = torch.tensor(encoder(text), dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:09:33.008819Z",
     "start_time": "2023-12-13T20:09:32.919896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "([35, 53, 59, 50, 42, 1, 63, 53, 59],\n tensor([[-0.1124,  1.0991],\n         [ 1.3969, -0.7540],\n         [-1.7231,  0.6022],\n         [-1.1804, -0.8145],\n         [ 0.7465,  1.0205],\n         [ 1.3840,  0.1378],\n         [ 0.7970,  0.4135],\n         [-0.8225,  2.6812],\n         [ 0.4293, -1.4945]]),\n torch.Size([9, 2]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "\n",
    "data = \"Would you\"\n",
    "input_length = len(data)\n",
    "input_embedding_dim = 2\n",
    "\n",
    "encoded_input = encoder(data)\n",
    "input_embedded = torch.randn(size=(len(data), input_embedding_dim))\n",
    "encoded_input, input_embedded, input_embedded.shape\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:12:44.301947Z",
     "start_time": "2023-12-13T20:12:44.296281Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0.1388, -0.7002, -0.7948],\n         [-4.7058,  3.7383, -1.3091],\n         [ 2.1729, -1.8441,  0.4379],\n         [ 2.2805, -1.4257,  1.1797],\n         [-2.1123,  1.0593, -1.4617],\n         [-4.6526,  3.6978, -1.2918],\n         [-3.6543,  2.8511, -1.0898],\n         [ 0.0156, -0.6871, -0.9489],\n         [-4.3369,  3.4907, -1.1423]]),\n tensor([[    0.0018,     0.0109,     0.0652,     0.6645,     0.0006,     0.0015,\n              0.0020,     0.0002,     0.2532],\n         [    0.0018,     0.0000,     0.0000,     0.0000,     0.0034,     0.0001,\n              0.0002,     0.9944,     0.0000],\n         [    0.0000,     0.0085,     0.0002,     0.1363,     0.0000,     0.0001,\n              0.0000,     0.0000,     0.8548],\n         [    0.0088,     0.3990,     0.0029,     0.0283,     0.0240,     0.1352,\n              0.0523,     0.0006,     0.3490],\n         [    0.0492,     0.0082,     0.4832,     0.2840,     0.0153,     0.0073,\n              0.0156,     0.1026,     0.0345],\n         [    0.0097,     0.0000,     0.0027,     0.0000,     0.0071,     0.0005,\n              0.0012,     0.9786,     0.0000],\n         [    0.0873,     0.0056,     0.1199,     0.0203,     0.0513,     0.0145,\n              0.0264,     0.6705,     0.0043],\n         [    0.0000,     0.0000,     0.0005,     0.8278,     0.0000,     0.0000,\n              0.0000,     0.0000,     0.1716],\n         [    0.0126,     0.0004,     0.0001,     0.0000,     0.0583,     0.0089,\n              0.0071,     0.9127,     0.0000]]))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 9x2  2x3 -> 9x3 * 3x9\n",
    "out_dimension = 3\n",
    "a = AttentionHead(input_embedding_dim, out_dimension)\n",
    "\n",
    "embeddings, scores = a(input_embedded) #9x3\n",
    "\n",
    "# 9x2 (Input) x 2x3 queries/keys -> 2x9 (Input) x 9x3 (All inputs transposed)  = 2x7 (Inputs weighted)\n",
    "# 9x7 (Q) x 9x7 (K) -> 9x7 7x9 (Inputs weighted x inputs weighted) -> 9x9 (Final input matrix)\n",
    "# 9x9 x 9x3 -> 9x3\n",
    "embeddings, scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T20:30:43.620809Z",
     "start_time": "2023-12-13T20:30:43.616753Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
